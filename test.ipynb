{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class XGBoostNode:\n",
    "    def __init__(self, similarity=float('-inf'), parent=None, left=None, right=None,\n",
    "                 feature_index=None, indices=None, output_val=None, split_value=None) -> None:\n",
    "        self.similarity = similarity\n",
    "        self.parent = parent\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.split_value = split_value\n",
    "        self.feature_index = feature_index\n",
    "        self.indices = [] if indices is None else indices\n",
    "        self.output_val = output_val\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Split Value:{self.split_value}\"\n",
    "\n",
    "\n",
    "class XGBoostRegression:\n",
    "\n",
    "    # Predict the residuals of the previous tree\n",
    "\n",
    "    def __init__(self, learning_rate: float = 0.1, gamma: float = 50, lmbda: float = 1.0, max_depth: int = 4, max_leaves: int = 4, n_trees: int = 4) -> None:\n",
    "        self.lmbda = lmbda\n",
    "        self.max_depth = max_depth\n",
    "        self.n_trees = n_trees\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_leaves = max_leaves\n",
    "        self.gamma = gamma\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.initial_guess = np.mean(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Aggregate predictions from all trees\n",
    "        predictions = np.full(len(X), self.initial_guess)\n",
    "        for tree in self.trees:\n",
    "            for i, data_point in enumerate(X):\n",
    "                predictions[i] += self._traverse_tree(tree, data_point)\n",
    "        return predictions\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # Calculate initial residuals\n",
    "        residuals = y - self.initial_guess\n",
    "\n",
    "        # Loop to create n trees\n",
    "        next_guesses = residuals\n",
    "        for tree_i in range(self.n_trees):\n",
    "            # Create the tree\n",
    "            new_tree = self._build_tree(residuals)\n",
    "\n",
    "            # Save the tree\n",
    "            self.trees.append(new_tree)\n",
    "\n",
    "            # Update predictions and residuals\n",
    "            for i in range(len(X)):\n",
    "                prediction = self.learning_rate*self._traverse_tree(\n",
    "                    new_tree, X[i]) + next_guesses[i]\n",
    "                residuals[i] = y[i] - prediction\n",
    "\n",
    "            # Update the initial guess for the next tree\n",
    "            next_guesses = residuals\n",
    "\n",
    "    def _prune_tree(self, node, residuals):\n",
    "        # Base case: if the node is a leaf\n",
    "        if node.left is None and node.right is None:\n",
    "            return self._calc_similarity_score(residuals[node.indices])\n",
    "\n",
    "        # Recursively prune the left and right subtrees\n",
    "        left_gain = self._prune_tree(node.left, residuals) if node.left else 0\n",
    "        right_gain = self._prune_tree(\n",
    "            node.right, residuals) if node.right else 0\n",
    "\n",
    "        # Calculate total gain with this split\n",
    "        total_gain = left_gain + right_gain - self.gamma\n",
    "\n",
    "        # Prune if gain is not sufficient\n",
    "        if total_gain < 0:\n",
    "            node.left = None\n",
    "            node.right = None\n",
    "            node.output_val = np.sum(residuals[node.indices]) / \\\n",
    "                (len(node.indices) + self.lmbda)\n",
    "            return 0\n",
    "\n",
    "        return total_gain\n",
    "\n",
    "    def _build_tree(self, residuals):\n",
    "        # Randomly select feature to sort by initially\n",
    "        rand_i = np.random.randint(0, self.X.shape[1])\n",
    "\n",
    "        # Sort indices based on the selected feature\n",
    "        sorted_indices = np.argsort(self.X[:, rand_i])\n",
    "\n",
    "        # Create root node with sorted indices\n",
    "        new_tree = XGBoostNode(similarity=self._calc_similarity_score(\n",
    "            residuals), indices=sorted_indices.tolist())\n",
    "\n",
    "        # Create queues to store nodes to check\n",
    "        current_level_queue = deque()\n",
    "        next_level_queue = deque()\n",
    "\n",
    "        current_level_queue.append(new_tree)\n",
    "\n",
    "        # Iterate until max depth\n",
    "        current_depth = 1\n",
    "        while current_depth < self.max_depth:\n",
    "            while current_level_queue:\n",
    "                curr_node = current_level_queue.pop()\n",
    "\n",
    "                # Randomly select feature to split by\n",
    "                rand_i = np.random.randint(0, self.X.shape[1])\n",
    "                curr_node.feature_index = rand_i\n",
    "\n",
    "                # Split on feature\n",
    "                left, right = self._split(residuals, curr_node, rand_i)\n",
    "\n",
    "                # Append children to next level queue if they exist\n",
    "                if left:\n",
    "                    next_level_queue.append(left)\n",
    "\n",
    "                if right:\n",
    "                    next_level_queue.append(right)\n",
    "\n",
    "            # Move to the next level\n",
    "            current_level_queue, next_level_queue = next_level_queue, deque()\n",
    "            current_depth += 1\n",
    "\n",
    "        # Process remaining nodes in the next level queue as leaves\n",
    "        while current_level_queue:\n",
    "            leaf_node = current_level_queue.pop()\n",
    "            leaf_node.output_val = np.sum(residuals[leaf_node.indices]) / \\\n",
    "                (len(leaf_node.indices) + self.lmbda)\n",
    "\n",
    "        # Post-prune the tree after building\n",
    "        self._prune_tree(new_tree, residuals)\n",
    "\n",
    "        return new_tree\n",
    "\n",
    "    def _traverse_tree(self, tree, data):\n",
    "        curr_node = tree\n",
    "        while curr_node.output_val == None:\n",
    "            if data[curr_node.feature_index] <= curr_node.split_value:\n",
    "                curr_node = curr_node.left\n",
    "            else:\n",
    "                curr_node = curr_node.right\n",
    "        return curr_node.output_val\n",
    "\n",
    "    def _split(self, residuals, node, feat_i):\n",
    "        # check if we can even split\n",
    "        if len(node.indices) <= 1:\n",
    "            # set output value\n",
    "            node.output_val = np.sum(residuals[node.indices]) / \\\n",
    "                (len(node.indices) + self.lmbda)\n",
    "            return None, None\n",
    "\n",
    "        # Grab the values for the given feature\n",
    "        vals = self.X[node.indices, feat_i]\n",
    "        local_residuals = residuals[node.indices]\n",
    "\n",
    "        # Get similarity score for root node\n",
    "        root_sim = node.similarity\n",
    "\n",
    "        best_gain = float('-inf')\n",
    "        left = None\n",
    "        right = None\n",
    "        # Try the split points for each value\n",
    "        for i in range(len(vals) - 1):\n",
    "            # Get split residual values\n",
    "            left_res = local_residuals[:i + 1]\n",
    "            right_res = local_residuals[i + 1:]\n",
    "\n",
    "            # Calculate similarity for left and right nodes\n",
    "            left_sim = self._calc_similarity_score(left_res)\n",
    "            right_sim = self._calc_similarity_score(right_res)\n",
    "\n",
    "            # Calculate gain for given split\n",
    "            gain = self._calc_gain(root_sim, left_sim, right_sim)\n",
    "\n",
    "            # Compare to best gain\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "\n",
    "                # Extract the indices for left and right nodes from the node's indices\n",
    "                left_indices = node.indices[:i + 1]\n",
    "                right_indices = node.indices[i + 1:]\n",
    "\n",
    "                # Create the left and right nodes\n",
    "                left = XGBoostNode(similarity=left_sim,\n",
    "                                   parent=node, indices=left_indices)\n",
    "                right = XGBoostNode(similarity=right_sim,\n",
    "                                    parent=node, indices=right_indices)\n",
    "\n",
    "                # set split value for current node\n",
    "                node.split_value = vals[i]\n",
    "\n",
    "        # Update children for root node\n",
    "        node.left = left\n",
    "        node.right = right\n",
    "\n",
    "        return left, right\n",
    "\n",
    "    def _calc_gain(self, root_sim, left_sim, right_sim):\n",
    "        return left_sim + right_sim - root_sim\n",
    "\n",
    "    def _calc_similarity_score(self, residuals):\n",
    "        # get sum of residuals squared\n",
    "        res_sq = np.square(np.sum(residuals))\n",
    "\n",
    "        # get number of residuals + lambda/regularization\n",
    "        n_residuals = len(residuals) + self.lmbda\n",
    "\n",
    "        return res_sq / n_residuals\n",
    "\n",
    "\n",
    "# Define a simple function to print the tree\n",
    "def print_tree(node, depth=0):\n",
    "    if node is not None:\n",
    "        # Print the current node's details\n",
    "        print(\" \" * 4 * depth +\n",
    "              f\"Depth {depth}: Node(similarity={node.similarity}, feature_index={node.feature_index}, split_value={node.split_value}, output_val={node.output_val}, indices={node.indices})\")\n",
    "\n",
    "        # Recursively print the left and right children\n",
    "        print_tree(node.left, depth + 1)\n",
    "        print_tree(node.right, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tree 0:\n",
      "Depth 0: Node(similarity=0.0, feature_index=0, split_value=-3, output_val=None, indices=[0, 3, 2, 1])\n",
      "    Depth 1: Node(similarity=112.5, feature_index=0, split_value=-5, output_val=None, indices=[0, 3])\n",
      "        Depth 2: Node(similarity=81.0, feature_index=None, split_value=None, output_val=-9.0, indices=[0])\n",
      "        Depth 2: Node(similarity=36.0, feature_index=None, split_value=None, output_val=-6.0, indices=[3])\n",
      "    Depth 1: Node(similarity=112.5, feature_index=0, split_value=8, output_val=None, indices=[2, 1])\n",
      "        Depth 2: Node(similarity=64.0, feature_index=None, split_value=None, output_val=8.0, indices=[2])\n",
      "        Depth 2: Node(similarity=49.0, feature_index=None, split_value=None, output_val=7.0, indices=[1])\n",
      "\n",
      "Tree 1:\n",
      "Depth 0: Node(similarity=4.000000000000002, feature_index=0, split_value=-3, output_val=None, indices=[0, 3, 2, 1])\n",
      "    Depth 1: Node(similarity=0.125, feature_index=0, split_value=-5, output_val=None, indices=[0, 3])\n",
      "        Depth 2: Node(similarity=0.009999999999999929, feature_index=None, split_value=None, output_val=-0.09999999999999964, indices=[0])\n",
      "        Depth 2: Node(similarity=0.16000000000000028, feature_index=None, split_value=None, output_val=-0.40000000000000036, indices=[3])\n",
      "    Depth 1: Node(similarity=6.1250000000000036, feature_index=0, split_value=8, output_val=None, indices=[2, 1])\n",
      "        Depth 2: Node(similarity=3.2400000000000024, feature_index=None, split_value=None, output_val=-1.8000000000000007, indices=[2])\n",
      "        Depth 2: Node(similarity=2.8900000000000006, feature_index=None, split_value=None, output_val=-1.7000000000000002, indices=[1])\n",
      "\n",
      "Tree 2:\n",
      "Depth 0: Node(similarity=0.04000000000000007, feature_index=0, split_value=-3, output_val=None, indices=[0, 3, 2, 1])\n",
      "    Depth 1: Node(similarity=135.30124999999998, feature_index=0, split_value=-5, output_val=None, indices=[0, 3])\n",
      "        Depth 2: Node(similarity=97.81210000000002, feature_index=None, split_value=None, output_val=-9.89, indices=[0])\n",
      "        Depth 2: Node(similarity=43.03359999999999, feature_index=None, split_value=None, output_val=-6.56, indices=[3])\n",
      "    Depth 1: Node(similarity=141.96125000000004, feature_index=0, split_value=8, output_val=None, indices=[2, 1])\n",
      "        Depth 2: Node(similarity=80.64040000000001, feature_index=None, split_value=None, output_val=8.98, indices=[2])\n",
      "        Depth 2: Node(similarity=61.9369, feature_index=None, split_value=None, output_val=7.87, indices=[1])\n",
      "\n",
      "Tree 3:\n",
      "Depth 0: Node(similarity=4.928399999999999, feature_index=0, split_value=-3, output_val=None, indices=[0, 3, 2, 1])\n",
      "    Depth 1: Node(similarity=0.5995125000000007, feature_index=0, split_value=-5, output_val=None, indices=[0, 3])\n",
      "        Depth 2: Node(similarity=0.7726410000000024, feature_index=None, split_value=None, output_val=0.8790000000000013, indices=[0])\n",
      "        Depth 2: Node(similarity=0.0466559999999997, feature_index=None, split_value=None, output_val=0.2159999999999993, indices=[3])\n",
      "    Depth 1: Node(similarity=15.318112500000002, feature_index=0, split_value=8, output_val=None, indices=[2, 1])\n",
      "        Depth 2: Node(similarity=8.282884000000001, feature_index=None, split_value=None, output_val=-2.878, indices=[2])\n",
      "        Depth 2: Node(similarity=7.059649, feature_index=None, split_value=None, output_val=-2.657, indices=[1])\n",
      "Prediction for [-5]: -19.111\n",
      "Prediction for [10]: 9.513\n",
      "Prediction for [8]: 11.302\n",
      "Prediction for [-3]: -13.744000000000002\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Sample Data\n",
    "X = np.array([[-5], [10], [8], [-3]])\n",
    "y = np.array([-10, 6, 7, -7])\n",
    "\n",
    "# Testing the model\n",
    "xgb_model = XGBoostRegression(max_depth=3, n_trees=4, gamma=0, lmbda=0)\n",
    "xgb_model.fit(X, y)\n",
    "xgb_model.train(X, y)\n",
    "\n",
    "# Print the structure of each built tree\n",
    "for i, tree in enumerate(xgb_model.trees):\n",
    "    print(f\"\\nTree {i}:\")\n",
    "    print_tree(tree)\n",
    "\n",
    "# Test predictions\n",
    "predictions = xgb_model.predict(X)\n",
    "for data_point, pred in zip(X, predictions):\n",
    "    print(f\"Prediction for {data_point}: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
